{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["fFbxa69CjjHb","ng3qPvlY9w0S","kEql7Bsw9105"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Libraries"],"metadata":{"id":"xuKV86zyM5JE"}},{"cell_type":"code","metadata":{"id":"5VxGrJjz9azU"},"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import numpy as np\n","import torch.nn.functional as F\n","from torchsummary import summary\n","from torch.nn import init\n","from skimage import morphology as morph\n","import torch.utils.model_zoo as model_zoo\n","import math\n","from skimage.morphology import watershed\n","from skimage.segmentation import find_boundaries\n","from scipy import ndimage"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EVXRyU12y8NE"},"source":["# Preparation"]},{"cell_type":"code","metadata":{"id":"meu_SynQIK4s"},"source":["# https://github.com/miguelvr/dropblock/blob/master/dropblock/dropblock.py\n","class DropBlock2D(nn.Module):\n","    def __init__(self, drop_prob, block_size):\n","        super(DropBlock2D, self).__init__()\n","        self.drop_prob = drop_prob\n","        self.block_size = block_size\n","    def forward(self, x):\n","        # shape: (bsize, channels, height, width)\n","        assert x.dim() == 4, \\\n","            \"Expected input with 4 dimensions (bsize, channels, height, width)\"\n","        if not self.training or self.drop_prob == 0.:\n","            return x\n","        else:\n","            # get gamma value\n","            gamma = self.drop_prob / (self.block_size ** 2)\n","            # sample mask\n","            mask = (torch.rand(x.shape[0], *x.shape[2:], device= x.device) < gamma).float()\n","            # compute block mask\n","            block_mask = self._compute_block_mask(mask)\n","            # apply block mask\n","            out = x * block_mask[:, None, :, :]\n","            # scale output\n","            out = out * block_mask.numel() / block_mask.sum()\n","            return out\n","    def _compute_block_mask(self, mask):\n","        block_mask = F.max_pool2d(input=mask[:, None, :, :],\n","                                  kernel_size=(self.block_size, self.block_size),\n","                                  stride=(1, 1),\n","                                  padding=self.block_size // 2)\n","\n","        if self.block_size % 2 == 0:\n","            block_mask = block_mask[:, :, :-1, :-1]\n","        block_mask = 1 - block_mask.squeeze(1)\n","        return block_mask\n","\n","class DropBlock3D(DropBlock2D):\n","    def __init__(self, drop_prob, block_size):\n","        super(DropBlock3D, self).__init__(drop_prob, block_size)\n","    def forward(self, x):\n","        # shape: (bsize, channels, depth, height, width)\n","        assert x.dim() == 5, \\\n","            \"Expected input with 5 dimensions (bsize, channels, depth, height, width)\"\n","        if not self.training or self.drop_prob == 0.:\n","            return x\n","        else:\n","            # get gamma value\n","            gamma = self.drop_prob / (self.block_size ** 3)\n","            # sample mask\n","            mask = (torch.rand(x.shape[0], *x.shape[2:]) < gamma).float()\n","            # place mask on input device\n","            mask = mask.to(x.device)\n","            # compute block mask\n","            block_mask = self._compute_block_mask(mask)\n","            # apply block mask\n","            out = x * block_mask[:, None, :, :, :]\n","            # scale output\n","            out = out * block_mask.numel() / block_mask.sum()\n","            return out\n","    def _compute_block_mask(self, mask):\n","        block_mask = F.max_pool3d(input=mask[:, None, :, :, :],\n","                                  kernel_size=(self.block_size, self.block_size, self.block_size),\n","                                  stride=(1, 1, 1),\n","                                  padding=self.block_size // 2)\n","        if self.block_size % 2 == 0:\n","            block_mask = block_mask[:, :, :-1, :-1, :-1]\n","        block_mask = 1 - block_mask.squeeze(1)\n","        return block_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4YtzETDt9LZx"},"source":["class CBAM(nn.Module):\n","    def __init__(self, in_channel, reduction_ratio = 8):\n","        super().__init__()\n","        self.hid_channel = max(1, in_channel // reduction_ratio)\n","        self.globalAvgPool = nn.AdaptiveAvgPool2d(1)\n","        self.globalMaxPool = nn.AdaptiveMaxPool2d(1)\n","        # Shared MLP.\n","        self.fc = nn.Sequential(nn.Conv2d(in_channel, self.hid_channel, 1, bias=False),\n","                               nn.Mish(),\n","                               nn.Conv2d(self.hid_channel, in_channel, 1, bias=False))\n","        self.sigmoid = nn.Sigmoid()\n","        self.conv1 = nn.Conv2d(2, 1, kernel_size=7, \n","                               stride=1, padding=3, bias=False)\n","    def forward(self, x):\n","        ''' Channel attention '''\n","        avgOut = self.fc(self.globalAvgPool(x))\n","        maxOut = self.fc(self.globalMaxPool(x))\n","        Mc = self.sigmoid(avgOut + maxOut)\n","        Mf1 = Mc * x\n","\n","        ''' Spatial attention. '''\n","        avg_out = torch.mean(Mf1, dim=1, keepdim=True)\n","        max_out, _ = torch.max(Mf1, dim=1, keepdim=True)\n","\n","        Ms = torch.cat([max_out, avg_out], dim=1)\n","        Ms = self.sigmoid(self.conv1(Ms))\n","        Mf2 = Ms * Mf1\n","        return Mf2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qaJr5QRJiv0C"},"source":["class ConvBn(nn.Sequential):\n","    def __init__(self, in_channel, out_channel, kernel_size = 3, \n","                 padding = 1, drop_block=False, block_size = 1, drop_prob = 0):\n","        super().__init__()\n","        self.add_module(\"conv\",nn.Conv2d(in_channel, out_channel, kernel_size, padding = padding,bias=False))\n","        if drop_block:\n","            self.add_module(\"drop_block\", DropBlock2D(block_size = block_size, drop_prob = drop_prob))\n","        self.add_module(\"bn\", nn.BatchNorm2d(out_channel))\n","        self.add_module(\"mish\", nn.Mish())\n","        self.add_module(\"cbam\", CBAM(out_channel))\n","\n","class DownSampleBlock(nn.Sequential):\n","    def __init__(self, in_channel, block_size = 1, drop_prob = 0):\n","        super().__init__()\n","        out_channel = in_channel // 2\n","        self.add_module(\"conv1\", nn.Conv2d(in_channel, out_channel, 1, bias=False))\n","        self.add_module(\"drop_block1\", DropBlock2D(block_size = block_size, drop_prob = drop_prob))\n","        self.add_module(\"bn\", nn.BatchNorm2d(out_channel))\n","        self.add_module(\"mish\", nn.Mish())\n","        self.add_module(\"cbam\", CBAM(out_channel))\n","        self.add_module(\"conv2\", nn.Conv2d(out_channel, out_channel, 2, 2, bias=False))\n","        self.add_module(\"drop_block2\", DropBlock2D(block_size = block_size, drop_prob = drop_prob))\n","\n","\n","class AttentionBlock(nn.Module):\n","    def __init__(self, in_channel, in_channel_skip, out_channel):\n","        super().__init__()\n","        self.conv_input = nn.Sequential(\n","            nn.Conv2d(in_channel, out_channel, 1, padding = 0, bias=False),\n","            nn.BatchNorm2d(out_channel),\n","            nn.ConvTranspose2d(out_channel, out_channel, 2, 2),\n","            CBAM(out_channel)\n","        )\n","        self.conv_skip = nn.Sequential(\n","            nn.Conv2d(in_channel_skip, out_channel, 1, bias = False),\n","            nn.BatchNorm2d(out_channel),\n","        )\n","        self.mixed_weight = nn.Sequential(\n","            nn.Mish(),\n","            nn.Conv2d(out_channel, 1, 1, bias = False),\n","            nn.BatchNorm2d(1),\n","            nn.Sigmoid()\n","        )\n","    def forward(self, x, skip):\n","        input_weight = self.conv_input(x)\n","        skip_weight = self.conv_skip(skip)\n","        output_weight = self.mixed_weight(input_weight + skip_weight)\n","        return output_weight * skip\n","\n","class DenseLayer(nn.Module):\n","    def __init__(self, in_channel, grow_rate):\n","        super().__init__()\n","        self.layer = nn.Sequential(\n","            ConvBn(in_channel, grow_rate*4,kernel_size=1, padding=0),\n","            ConvBn(grow_rate*4, grow_rate)\n","        )\n","    def forward(self, x):\n","        output = self.layer(x)\n","        return torch.cat([output, x], dim = 1)\n","\n","class DenseBlock(nn.Sequential):\n","    def __init__(self, in_channel, grow_rate, repetition):\n","        super().__init__()\n","        for i in range(repetition):\n","            layer = DenseLayer(in_channel+i*grow_rate, grow_rate)\n","            self.add_module(f\"dense_layer_{i+1}\", layer)\n","\n","class DecoderBlock(nn.Module):\n","    def __init__(self, in_channel, in_channel_skip, out_channel, \n","                 block_size = 1, drop_prob = 0):\n","        super().__init__()\n","        self.conv_trans = nn.ConvTranspose2d(in_channel, out_channel, 2, 2)\n","        self.attention = AttentionBlock(in_channel, in_channel_skip, out_channel)\n","        self.convbn = ConvBn(in_channel_skip + out_channel, out_channel, drop_block=True,\n","                            block_size = block_size, drop_prob = drop_prob)\n","    \n","    def forward(self, x, skip):\n","        output = self.conv_trans(x)\n","        attention = self.attention(x, skip)\n","        output = torch.cat([output, attention], dim=1)\n","        return self.convbn(output)\n","\n","class UpsampleBlock(nn.Sequential):\n","    def __init__(self,  in_channel, out_channel, times):\n","        super().__init__()\n","        for i in range(times):\n","            channel = in_channel if i == 0 else out_channel\n","            self.add_module(f\"convtrans{i+1}\", nn.ConvTranspose2d(channel, out_channel, 2, 2))\n","            self.add_module(f\"cbam{i+1}\", CBAM(out_channel))  "],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class conv_block(nn.Sequential):\n","    def __init__(self, ch_in, ch_out, kernel_size = 3, \n","                 padding = 1, drop_block=False, block_size = 1, drop_prob = 0):\n","        super().__init__()\n","        self.add_module(\"conv1\",nn.Conv2d(ch_in, ch_out, kernel_size, padding = padding,bias=False))\n","        self.add_module(\"bn1\", nn.BatchNorm2d(ch_out))\n","        self.add_module(\"relu1\", nn.ReLU(inplace=True)) \n","        self.add_module(\"conv2\",nn.Conv2d(ch_out, ch_out, kernel_size, padding = padding,bias=False))\n","        if drop_block:\n","            self.add_module(\"drop_block\", DropBlock2D(block_size = block_size, drop_prob = drop_prob))\n","        self.add_module(\"bn2\", nn.BatchNorm2d(ch_out))\n","        self.add_module(\"relu2\", nn.ReLU(inplace=True)) \n","\n","class up_conv(nn.Module):\n","    def __init__(self,ch_in,ch_out):\n","        super(up_conv,self).__init__()\n","        self.up = nn.Sequential(\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(ch_in,ch_out,kernel_size=2,stride=1,padding=\"same\",bias=False,),\n","\t\t    nn.BatchNorm2d(ch_out),\n","\t\t\tnn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self,x):\n","        x = self.up(x)\n","        return x"],"metadata":{"id":"VwtIK1LoByvw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Residual(nn.Module):\n","    def __init__(self, fn):\n","        super().__init__()\n","        self.fn = fn\n","\n","    def forward(self, x):\n","        return self.fn(x) + x\n","\n","def ConvMixer(dim, depth, kernel_size=9, patch_size=7):\n","    return nn.Sequential(\n","        nn.Conv2d(dim, dim, kernel_size=patch_size, stride=patch_size),\n","        nn.GELU(),\n","        nn.BatchNorm2d(dim),\n","        *[nn.Sequential(\n","                Residual(nn.Sequential(\n","                    nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"),\n","                    nn.GELU(),\n","                    nn.BatchNorm2d(dim)\n","                )),\n","                nn.Conv2d(dim, dim, kernel_size=1),\n","                nn.GELU(),\n","                nn.BatchNorm2d(dim)\n","        ) for i in range(depth)])\n","        #nn.AdaptiveAvgPool2d((1,1)),\n","        #nn.Flatten(),\n","        #nn.Linear(dim, n_classes))"],"metadata":{"id":"L02IukqDDYoY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Attention_block(nn.Module):\n","    def __init__(self,F_g,F_l,F_int):\n","        super(Attention_block,self).__init__()\n","        self.W_g = nn.Sequential(\n","            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(F_int)\n","            )\n","        \n","        self.W_x = nn.Sequential(\n","            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(F_int)\n","        )\n","\n","        self.psi = nn.Sequential(\n","            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(1),\n","            nn.Sigmoid()\n","        )\n","        \n","        self.relu = nn.ReLU(inplace=True)\n","        \n","    def forward(self,g,x):\n","        g1 = self.W_g(g)\n","        x1 = self.W_x(x)\n","        psi = self.relu(g1+x1)\n","        psi = self.psi(psi)\n","\n","        return x*psi"],"metadata":{"id":"Mwd7kxpkjeMh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''class Conv2d(nn.Module):\n","    def __init__(self, pdc, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n","        super(Conv2d, self).__init__()\n","        if in_channels % groups != 0:\n","            raise ValueError('in_channels must be divisible by groups')\n","        if out_channels % groups != 0:\n","            raise ValueError('out_channels must be divisible by groups')\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","        self.dilation = dilation\n","        self.groups = groups\n","        self.weight = nn.Parameter(torch.Tensor(out_channels, in_channels // groups, kernel_size, kernel_size))\n","        if bias:\n","            self.bias = nn.Parameter(torch.Tensor(out_channels))\n","        else:\n","            self.register_parameter('bias', None)\n","        self.reset_parameters()\n","        self.pdc = pdc\n","\n","    def reset_parameters(self):\n","        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n","        if self.bias is not None:\n","            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n","            bound = 1 / math.sqrt(fan_in)\n","            nn.init.uniform_(self.bias, -bound, bound)\n","\n","    def forward(self, input):\n","\n","        return self.pdc(input, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)'''"],"metadata":{"id":"HAr58rQrrWsC","colab":{"base_uri":"https://localhost:8080/","height":154},"executionInfo":{"status":"ok","timestamp":1648128269381,"user_tz":-420,"elapsed":53,"user":{"displayName":"Hai Ninh Nham Do","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj71NWKYnSKJmvjkMKuN-TGjfdJzXtd8JZNf4r7=s64","userId":"15777938739034634289"}},"outputId":"7c924332-9f84-40c7-cade-02a105c719b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"class Conv2d(nn.Module):\\n    def __init__(self, pdc, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\\n        super(Conv2d, self).__init__()\\n        if in_channels % groups != 0:\\n            raise ValueError('in_channels must be divisible by groups')\\n        if out_channels % groups != 0:\\n            raise ValueError('out_channels must be divisible by groups')\\n        self.in_channels = in_channels\\n        self.out_channels = out_channels\\n        self.kernel_size = kernel_size\\n        self.stride = stride\\n        self.padding = padding\\n        self.dilation = dilation\\n        self.groups = groups\\n        self.weight = nn.Parameter(torch.Tensor(out_channels, in_channels // groups, kernel_size, kernel_size))\\n        if bias:\\n            self.bias = nn.Parameter(torch.Tensor(out_channels))\\n        else:\\n            self.register_parameter('bias', None)\\n        self.reset_parameters()\\n        self.pdc = pdc\\n\\n    def reset_parameters(self):\\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\\n        if self.bias is not None:\\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\\n            bound = 1 / math.sqrt(fan_in)\\n            nn.init.uniform_(self.bias, -bound, bound)\\n\\n    def forward(self, input):\\n\\n        return self.pdc(input, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["class _ASPPModule(nn.Module):\n","    def __init__(self, inplanes, planes, kernel_size, padding, dilation, BatchNorm):\n","        super().__init__()\n","        self.atrous_conv = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n","                                      stride=1, padding=padding, dilation=dilation, bias=False)\n","        self.bn = BatchNorm(planes)\n","        self.silu = nn.SiLU(inplace=True)\n","        self._init_weight()\n","\n","    def forward(self, x):\n","        x = self.atrous_conv(x)\n","        x = self.bn(x)\n","\n","        return self.silu(x)\n","\n","    def _init_weight(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                torch.nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class ASPP(nn.Module):\n","    def __init__(self, inplanes, outplanes, output_stride, BatchNorm):\n","        super().__init__()\n","        if output_stride == 4:\n","            dilations = [1, 6, 12, 18]\n","        elif output_stride == 8:\n","            dilations = [1, 4, 6, 10]\n","        elif output_stride == 2:\n","            dilations = [1, 12, 24, 36]\n","        else:\n","            raise NotImplementedError\n","\n","        #self.aspp1 = _ASPPModule(inplanes, outplanes, 1, padding=0,dilation=dilations[0], BatchNorm=BatchNorm)\n","        self.aspp2 = _ASPPModule(inplanes, outplanes, 3, padding=dilations[1], dilation=dilations[1], BatchNorm=BatchNorm)\n","        self.aspp3 = _ASPPModule(inplanes, outplanes, 3, padding=dilations[2], dilation=dilations[2], BatchNorm=BatchNorm)\n","        self.aspp4 = _ASPPModule(inplanes, outplanes, 3, padding=dilations[3], dilation=dilations[3], BatchNorm=BatchNorm)\n","\n","        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n","                                             nn.Conv2d(inplanes, outplanes, 1, stride=1, bias=False),\n","                                             #BatchNorm(outplanes),\n","                                             nn.SiLU(inplace=True))\n","        self.conv1 = nn.Conv2d(outplanes*4, outplanes, 1, bias=False)\n","        self.bn1 = BatchNorm(outplanes)\n","        self.silu = nn.SiLU(inplace=True)\n","        self.dropout = nn.Dropout(0.0)\n","        self._init_weight()\n","\n","    def forward(self, x):\n","        #x1 = self.aspp1(x)\n","        x2 = self.aspp2(x)\n","        x3 = self.aspp3(x)\n","        x4 = self.aspp4(x)\n","        x5 = self.global_avg_pool(x)\n","        x5 = F.interpolate(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n","        x = torch.cat((x2, x3, x4, x5), dim=1)\n","\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.silu(x)\n","\n","        return self.dropout(x)\n","  \n","    def _init_weight(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                torch.nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class PASPP(nn.Module):\n","    def __init__(self, inplanes, outplanes, output_stride=4, BatchNorm=nn.BatchNorm2d):\n","        super().__init__()\n","        if output_stride == 4:\n","            dilations = [1, 6, 12, 18]\n","        elif output_stride == 8:\n","            dilations = [1, 4, 6, 10]\n","        elif output_stride == 2:\n","            dilations = [1, 12, 24, 36]\n","        elif output_stride == 16:\n","            dilations = [1, 2, 3, 4]\n","        elif output_stride == 1:\n","            dilations = [1, 16, 32, 48]\n","        else:\n","            raise NotImplementedError\n","        self._norm_layer = BatchNorm\n","        self.silu = nn.SiLU(inplace=True)\n","        self.conv1 = self._make_layer(inplanes, inplanes // 4)\n","        self.conv2 = self._make_layer(inplanes, inplanes // 4)\n","        self.conv3 = self._make_layer(inplanes, inplanes // 4)\n","        self.conv4 = self._make_layer(inplanes, inplanes // 4)\n","        self.atrous_conv1 = nn.Conv2d(inplanes // 4, inplanes // 4, kernel_size=3, dilation=dilations[0], padding=dilations[0])\n","        self.atrous_conv2 = nn.Conv2d(inplanes // 4, inplanes // 4, kernel_size=3, dilation=dilations[1], padding=dilations[1])\n","        self.atrous_conv3 = nn.Conv2d(inplanes // 4, inplanes // 4, kernel_size=3, dilation=dilations[2], padding=dilations[2])\n","        self.atrous_conv4 = nn.Conv2d(inplanes // 4, inplanes // 4, kernel_size=3, dilation=dilations[3], padding=dilations[3])\n","        self.conv5 = self._make_layer(inplanes // 2, inplanes // 2)\n","        self.conv6 = self._make_layer(inplanes // 2, inplanes // 2)\n","        self.convout = self._make_layer(inplanes, inplanes)\n","    \n","    def _make_layer(self, inplanes, outplanes):\n","        layer = []\n","        layer.append(nn.Conv2d(inplanes, outplanes, kernel_size = 1))\n","        layer.append(self._norm_layer(outplanes))\n","        layer.append(self.silu)\n","        return nn.Sequential(*layer)\n","    \n","    def forward(self, X):\n","        x1 = self.conv1(X)\n","        x2 = self.conv2(X)\n","        x3 = self.conv3(X)\n","        x4 = self.conv4(X)\n","        \n","        x12 = torch.add(x1, x2)\n","        x34 = torch.add(x3, x4)\n","        \n","        x1 = torch.add(self.atrous_conv1(x1),x12)\n","        x2 = torch.add(self.atrous_conv2(x2),x12)\n","        x3 = torch.add(self.atrous_conv3(x3),x34)\n","        x4 = torch.add(self.atrous_conv4(x4),x34)\n","        \n","        x12 = torch.cat([x1, x2], dim = 1)\n","        x34 = torch.cat([x3, x4], dim = 1)\n","        \n","        x12 = self.conv5(x12)\n","        x34 = self.conv5(x34)\n","        x = torch.cat([x12, x34], dim=1)\n","        x = self.convout(x)\n","        return x "],"metadata":{"id":"iC3nOazVwaBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class activation_block(nn.Module):\n","  def __init__(self, outplane):\n","    super(activation_block, self).__init__()\n","    self.gelu = nn.GELU()\n","    self.outplane = outplane\n","    self.batchnorm = nn.BatchNorm2d(outplane)\n","  \n","  def forward(self, x):\n","    x = self.gelu(x)\n","    x = self.batchnorm(x)\n","    return x\n","\n","class conv_stem(nn.Module):\n","  def __init__(self, inplane, outplane, patch_size):\n","    super(conv_stem, self).__init__()\n","    self.inplane = inplane\n","    self.outplane = outplane\n","    self.patch_size = patch_size\n","    self.conv = nn.Conv2d(self.inplane, self.outplane, kernel_size=self.patch_size, stride=self.patch_size)\n","    self.activation = activation_block(self.outplane)\n","\n","  def forward(self, x):\n","    x = self.conv(x)\n","    x = self.activation(x)\n","    return x\n","\n","class DepthwiseConv2d(nn.Module):\n","  def __init__(self, inplane, kernels_per_layer, outplane):\n","    super(DepthwiseConv2d, self).__init__()\n","    self.inplane = inplane\n","    self.outplane = outplane\n","    self.kernels_per_layer = kernels_per_layer\n","    self.depthwise = nn.Conv2d(self.inplane, self.inplane * self.kernels_per_layer, kernel_size=3, padding=1, groups=self.inplane)\n","    #self.pointwise = nn.Conv2d(nin * kernels_per_layer, nout, kernel_size=1)\n","\n","  def forward(self, x):\n","    out = self.depthwise(x)\n","    #out = self.pointwise(out)\n","    return out\n","\n","class ConvMixer(nn.Module):\n","  def __init__(self, inplane, kernels_per_layer, outplane, kernels_size):\n","    super(ConvMixer, self).__init__()\n","    self.inplane = inplane\n","    self.outplane = outplane\n","    self.kernels_per_layer = kernels_per_layer\n","    self.kernel_size = kernels_size\n","    self.depthwise = DepthwiseConv2d(self.inplane, self.kernels_per_layer, self.outplane)\n","    self.pointwise = nn.Conv2d(self.inplane * self.kernels_per_layer, self.outplane, kernel_size=1)\n","    self.activation = activation_block(self.outplane)\n","\n","  def forward(self, x):\n","    #Depthwise convolution\n","    x0 = x\n","    x = self.depthwise(x)\n","    x = x + x0 #Residual\n","\n","    #Pointwise convolution\n","    x = self.pointwise(x)\n","    x = self.activation(x)\n","    return x \n","\n","'''def get_conv_mixer_256_8(image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=10):\n","    inputs = keras.Input((image_size, image_size, 3))\n","    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n","\n","    # Extract patch embeddings.\n","    x = conv_stem(x, filters, patch_size)\n","\n","    # ConvMixer blocks.\n","    for _ in range(depth):\n","        x = conv_mixer_block(x, filters, kernel_size)\n","\n","    # Classification block.\n","    x = layers.GlobalAvgPool2D()(x)\n","    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n","\n","    return keras.Model(inputs, outputs)'''"],"metadata":{"id":"UFzNmTk2ZbH9","colab":{"base_uri":"https://localhost:8080/","height":103},"executionInfo":{"status":"ok","timestamp":1648128269383,"user_tz":-420,"elapsed":41,"user":{"displayName":"Hai Ninh Nham Do","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj71NWKYnSKJmvjkMKuN-TGjfdJzXtd8JZNf4r7=s64","userId":"15777938739034634289"}},"outputId":"4ebb7587-5fe1-4499-9e76-4683e5558f97"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'def get_conv_mixer_256_8(image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=10):\\n    inputs = keras.Input((image_size, image_size, 3))\\n    x = layers.Rescaling(scale=1.0 / 255)(inputs)\\n\\n    # Extract patch embeddings.\\n    x = conv_stem(x, filters, patch_size)\\n\\n    # ConvMixer blocks.\\n    for _ in range(depth):\\n        x = conv_mixer_block(x, filters, kernel_size)\\n\\n    # Classification block.\\n    x = layers.GlobalAvgPool2D()(x)\\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\\n\\n    return keras.Model(inputs, outputs)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"R0Y-1yUp9rYB"}},{"cell_type":"markdown","source":["## Attention U-Net"],"metadata":{"id":"fFbxa69CjjHb"}},{"cell_type":"code","source":["class Attention_UNet(nn.Module):\n","    def __init__(self,img_ch=3,output_ch=2, drop_prob=0):\n","        super(AttU_Net,self).__init__()\n","        \n","        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n","\n","        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n","        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n","        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n","        self.Conv4 = conv_block(ch_in=256,ch_out=512, drop_block=True, block_size = 5, drop_prob = drop_prob)\n","        self.Conv5 = conv_block(ch_in=512,ch_out=1024, drop_block=True, block_size = 5, drop_prob = drop_prob)\n","\n","        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n","        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n","        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n","\n","        self.Up4 = up_conv(ch_in=512,ch_out=256)\n","        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n","        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n","        \n","        self.Up3 = up_conv(ch_in=256,ch_out=128)\n","        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n","        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n","        \n","        self.Up2 = up_conv(ch_in=128,ch_out=64)\n","        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n","        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n","\n","        self.Conv_1x1 = nn.Sequential(\n","            nn.Conv2d(64, output_ch, kernel_size=1,stride=1,padding=0), \n","            nn.Softmax(dim=1)\n","            )\n","\n","    def forward(self,x):\n","        # encoding path\n","        x1 = self.Conv1(x)\n","\n","        x2 = self.Maxpool(x1)\n","        x2 = self.Conv2(x2)\n","        \n","        x3 = self.Maxpool(x2)\n","        x3 = self.Conv3(x3)\n","\n","        x4 = self.Maxpool(x3)\n","        x4 = self.Conv4(x4)\n","\n","        x5 = self.Maxpool(x4)\n","        x5 = self.Conv5(x5)\n","\n","        # decoding + concat path\n","        d5 = self.Up5(x5)\n","        x4 = self.Att5(d5,x4)\n","        d5 = torch.cat((x4,d5),dim=1)        \n","        d5 = self.Up_conv5(d5)\n","        \n","        d4 = self.Up4(d5)\n","        x3 = self.Att4(d4,x3)\n","        d4 = torch.cat((x3,d4),dim=1)\n","        d4 = self.Up_conv4(d4)\n","\n","        d3 = self.Up3(d4)\n","        x2 = self.Att3(d3,x2)\n","        d3 = torch.cat((x2,d3),dim=1)\n","        d3 = self.Up_conv3(d3)\n","\n","        d2 = self.Up2(d3)\n","        x1 = self.Att2(d2,x1)\n","        d2 = torch.cat((x1,d2),dim=1)\n","        d2 = self.Up_conv2(d2)\n","\n","        d1 = self.Conv_1x1(d2)\n","\n","        return d1"],"metadata":{"id":"YrEyEnBmjmgi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Proposed"],"metadata":{"id":"ng3qPvlY9w0S"}},{"cell_type":"code","metadata":{"id":"rI9bdb4CCHxO"},"source":["class SegNet(nn.Module):\n","    def __init__(self, input_channel = 3, in_channel = 32, \n","                 num_classes = 2, drop_prob = 0):\n","        super().__init__()\n","        self.conv1 = nn.Sequential(\n","            ConvBn(input_channel, in_channel),\n","            ConvBn(in_channel, in_channel)\n","        )\n","        grow_list = [16, 32, 64, 64, 64]\n","        repetition_list = [6, 6, 6, 6, 6]\n","        block_list = [5, 4, 3, 2]\n","        ch_decoder = [256, 128, 64, 32]\n","        in_ch_skip = []\n","        self.dense_list = nn.ModuleList()\n","        self.downsample_list = nn.ModuleList()\n","        self.decoder_list = nn.ModuleList()\n","        self.up_sample_list = nn.ModuleList()\n","\n","        for i in range(4):\n","            self.dense_list.append(DenseBlock(in_channel, grow_list[i], repetition_list[i]))\n","            in_channel += repetition_list[i] * grow_list[i]\n","            in_ch_skip.append(in_channel)\n","            self.downsample_list.append(DownSampleBlock(in_channel, block_list[i], drop_prob))\n","            in_channel = in_channel // 2\n","\n","        i+=1\n","        self.bottle_neck = DenseBlock(in_channel, grow_list[i], repetition_list[i])\n","        in_channel += repetition_list[i] * grow_list[i]\n","        for i in range(4):\n","            self.decoder_list.append(DecoderBlock(in_channel, in_ch_skip[-i-1], ch_decoder[i],\n","                                                  block_list[-i-1], drop_prob))\n","            self.up_sample_list.append(UpsampleBlock(in_channel, num_classes, 4-i))\n","            in_channel = ch_decoder[i]\n","        in_channel += 4 * num_classes\n","\n","        self.conv2 = nn.Sequential(\n","            nn.BatchNorm2d(in_channel),\n","            nn.Mish(),\n","            nn.Conv2d(in_channel, num_classes, kernel_size=1, padding=0),\n","            nn.Softmax(dim=1)\n","            )\n","        \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        encoder_for_cat = []\n","        output_cat = []\n","        for i in range(4):\n","            x = self.dense_list[i](x)\n","            encoder_for_cat.append(x)\n","            x = self.downsample_list[i](x)\n","        x = self.bottle_neck(x)\n","        #x = self.middle(x)\n","        output_cat.append(self.up_sample_list[0](x))\n","        for i in range(4):\n","            x = self.decoder_list[i](x, encoder_for_cat[-i-1])\n","            if i < 3:\n","                output_cat.append(self.up_sample_list[i+1](x))\n","        output_cat.append(x)\n","        output = torch.cat(output_cat, dim=1)\n","        output = self.conv2(output)\n"," \n","        return output\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## draft"],"metadata":{"id":"kEql7Bsw9105"}},{"cell_type":"code","source":["class U_Net_mixer(nn.Module):\n","    def __init__(self,img_ch=3,output_ch=2, drop_prob = 0):\n","        super(U_Net_mixer,self).__init__()\n","        \n","        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n","        channel = 64\n","        self.Conv1 = conv_block(ch_in=img_ch,ch_out=channel)\n","        self.Conv2 = conv_block(ch_in=channel,ch_out=channel*2)\n","        self.Conv3 = conv_block(ch_in=channel*2,ch_out=channel*4)\n","        self.Conv4 = conv_block(ch_in=channel*4,ch_out=channel*8, drop_block=True, block_size = 5, drop_prob = drop_prob)\n","        self.Conv5 = conv_block(ch_in=channel*8,ch_out=channel*16, drop_block=True, block_size = 3, drop_prob = drop_prob)\n","\n","        self.middle = ConvMixer(channel*16, 1, 9, 7)\n","\n","        self.Up5 = up_conv(ch_in=channel*16,ch_out=channel*8)\n","        self.Up_conv5 = conv_block(ch_in=channel*16, ch_out=channel*8)\n","\n","        self.Up4 = up_conv(ch_in=channel*8,ch_out=channel*4)\n","        self.Up_conv4 = conv_block(ch_in=channel*8, ch_out=channel*4)\n","        \n","        self.Up3 = up_conv(ch_in=channel*4,ch_out=channel*2)\n","        self.Up_conv3 = conv_block(ch_in=channel*4, ch_out=channel*2)\n","        \n","        self.Up2 = up_conv(ch_in=channel*2,ch_out=channel)\n","        self.Up_conv2 = conv_block(ch_in=channel*2, ch_out=channel)\n","\n","        self.Conv_1x1 = nn.Sequential(\n","            nn.Conv2d(channel, output_ch,kernel_size=1,stride=1,padding=0), \n","            nn.Softmax(dim=1)\n","            )\n","\n","\n","    def forward(self,x):\n","        # encoding path\n","        x1 = self.Conv1(x)\n","\n","        x2 = self.Maxpool(x1)\n","        x2 = self.Conv2(x2)\n","        \n","        x3 = self.Maxpool(x2)\n","        x3 = self.Conv3(x3)\n","\n","        x4 = self.Maxpool(x3)\n","        x4 = self.Conv4(x4)\n","\n","        x5 = self.Maxpool(x4)\n","        x5 = self.Conv5(x5)\n","\n","        #x5 = self.middle(x5)\n","\n","        # decoding + concat path\n","        d5 = self.Up5(x5)\n","        d5 = torch.cat((x4,d5),dim=1)\n","        d5 = self.Up_conv5(d5)\n","        \n","        d4 = self.Up4(d5)\n","        d4 = torch.cat((x3,d4),dim=1)\n","        d4 = self.Up_conv4(d4)\n","\n","        d3 = self.Up3(d4)\n","        d3 = torch.cat((x2,d3),dim=1)\n","        d3 = self.Up_conv3(d3)\n","\n","        d2 = self.Up2(d3)\n","        d2 = torch.cat((x1,d2),dim=1)\n","        d2 = self.Up_conv2(d2)\n","\n","        d1 = self.Conv_1x1(d2)\n","\n","        return d1"],"metadata":{"id":"8iBp5Sm493_G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Modified PiDiNet"],"metadata":{"id":"XpwYPFZij5Na"}},{"cell_type":"code","source":["class CSAM(nn.Module):\n","    \"\"\"\n","    Compact Spatial Attention Module\n","    \"\"\"\n","    def __init__(self, channels):\n","        super(CSAM, self).__init__()\n","\n","        mid_channels = 4\n","        self.relu1 = nn.ReLU()\n","        self.conv1 = nn.Conv2d(channels, mid_channels, kernel_size=1, padding=0)\n","        self.conv2 = nn.Conv2d(mid_channels, 1, kernel_size=3, padding=1, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","        nn.init.constant_(self.conv1.bias, 0)\n","\n","    def forward(self, x):\n","        y = self.relu1(x)\n","        y = self.conv1(y)\n","        y = self.conv2(y)\n","        y = self.sigmoid(y)\n","\n","        return x * y\n","\n","class CDCM(nn.Module):\n","    \"\"\"\n","    Compact Dilation Convolution based Module\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels):\n","        super(CDCM, self).__init__()\n","\n","        self.relu1 = nn.ReLU()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0)\n","        self.conv2_1 = nn.Conv2d(out_channels, out_channels, kernel_size=3, dilation=5, padding=5, bias=False)\n","        self.conv2_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, dilation=7, padding=7, bias=False)\n","        self.conv2_3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, dilation=9, padding=9, bias=False)\n","        self.conv2_4 = nn.Conv2d(out_channels, out_channels, kernel_size=3, dilation=11, padding=11, bias=False)\n","        nn.init.constant_(self.conv1.bias, 0)\n","        \n","    def forward(self, x):\n","        x = self.relu1(x)\n","        x = self.conv1(x)\n","        x1 = self.conv2_1(x)\n","        x2 = self.conv2_2(x)\n","        x3 = self.conv2_3(x)\n","        x4 = self.conv2_4(x)\n","        return x1 + x2 + x3 + x4\n","\n","class MapReduce(nn.Module):\n","    \"\"\"\n","    Reduce feature maps into a single edge map\n","    \"\"\"\n","    def __init__(self, channels):\n","        super(MapReduce, self).__init__()\n","        self.conv = nn.Conv2d(channels, 2, kernel_size=1, padding=0)\n","        nn.init.constant_(self.conv.bias, 0)\n","\n","    def forward(self, x):\n","        return self.conv(x)"],"metadata":{"id":"-pB0UcKwpGaA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PiDiNet(nn.Module):\n","    def __init__(self, img_channel=3, inplane=32, num_classes=2, dil=8, sa=True, ta=True, drop_prob = 0): #dil=None, sa=False; inplane luc dau muon depth tu 3 len 32/64, pdcs\n","        super(PiDiNet, self).__init__()\n","        self.sa = sa\n","        self.ta = ta\n","        if dil is not None:\n","            assert isinstance(dil, int), 'dil should be an int'\n","        self.dil = dil\n","\n","        self.fuseplanes = []\n","\n","        self.inplane = inplane\n","        self.img_channel = img_channel\n","        self.num_classes = num_classes\n","        self.drop_prob = drop_prob\n","\n","        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n","        self.Conv5 = conv_block(ch_in=self.inplane*8,ch_out=self.inplane*16, drop_block=True, block_size = 3, drop_prob = self.drop_prob)\n","        self.middle_1 = conv_stem(inplane=self.inplane*16, outplane=self.inplane*16, patch_size=2)\n","        self.middle_2 = ConvMixer(inplane=self.inplane*16, kernels_per_layer=1, outplane=self.inplane*16, kernels_size=5)\n","        self.softmax = nn.Softmax(dim=1)\n","        \n","        self.init_block = nn.Conv2d(self.img_channel, self.inplane, kernel_size=3, padding=1) #x1->32\n","        self.aspp = PASPP(self.inplane*16,self.inplane*16,16) \n","\n","        self.Conv1 = conv_block(ch_in=self.img_channel,ch_out=self.inplane)\n","        self.Up2 = up_conv(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.Att2 = Attention_block(F_g=self.inplane,F_l=self.inplane,F_int=self.inplane//2)\n","        self.Up_conv2 = conv_block(ch_in=self.inplane*2, ch_out=self.inplane)\n","        self.fuseplanes.append(self.inplane) # C\n","\n","        inplane = self.inplane\n","        self.inplane = self.inplane * 2 #x2->64\n","        self.Conv2 = conv_block(ch_in=self.inplane//2,ch_out=self.inplane)\n","        self.Up3 = up_conv(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.Att3 = Attention_block(F_g=self.inplane,F_l=self.inplane,F_int=self.inplane//2)\n","        self.Up_conv3 = conv_block(ch_in=self.inplane*2, ch_out=self.inplane)\n","        self.fuseplanes.append(self.inplane) # 2C\n","        \n","        inplane = self.inplane\n","        self.inplane = self.inplane * 2 #x4->128\n","        self.Conv3 = conv_block(ch_in=self.inplane//2,ch_out=self.inplane)\n","        self.Up4 = up_conv(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.Att4 = Attention_block(F_g=self.inplane,F_l=self.inplane,F_int=self.inplane//2)\n","        self.Up_conv4 = conv_block(ch_in=self.inplane*2,ch_out=self.inplane)  \n","        self.fuseplanes.append(self.inplane) # 4C\n","\n","        inplane = self.inplane\n","        self.inplane = self.inplane * 2 #x8->256\n","        self.Conv4 = conv_block(ch_in=self.inplane//2,ch_out=self.inplane, drop_block=True, block_size = 5, drop_prob = self.drop_prob)\n","        self.Up5 = up_conv(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.Att5 = Attention_block(F_g=self.inplane,F_l=self.inplane,F_int=self.inplane//2)\n","        self.Up_conv5 = conv_block(ch_in=self.inplane*2,ch_out=self.inplane)    \n","        self.fuseplanes.append(self.inplane) # 8C\n","\n","        self.conv_reduces = nn.ModuleList()\n","        if self.sa and self.dil is not None:\n","            self.attentions = nn.ModuleList()\n","            self.dilations = nn.ModuleList()\n","            for i in range(4):\n","                self.dilations.append(CDCM(self.fuseplanes[i], self.dil))\n","                self.attentions.append(CSAM(self.dil))\n","                self.conv_reduces.append(MapReduce(self.dil))\n","        elif self.sa:\n","            self.attentions = nn.ModuleList()\n","            for i in range(4):\n","                self.attentions.append(CSAM(self.fuseplanes[i]))\n","                self.conv_reduces.append(MapReduce(self.fuseplanes[i]))\n","        elif self.dil is not None:\n","            self.dilations = nn.ModuleList()\n","            for i in range(4):\n","                self.dilations.append(CDCM(self.fuseplanes[i], self.dil))\n","                self.conv_reduces.append(MapReduce(self.dil))\n","        else:\n","            for i in range(4):\n","                self.conv_reduces.append(MapReduce(self.fuseplanes[i]))\n","\n","        #self.classifier = nn.Conv2d(4, 1, kernel_size=1)\n","        self.classifier = nn.Sequential(\n","            nn.Conv2d(8, self.num_classes, kernel_size=1,stride=1,padding=0), nn.Softmax(dim=1))\n","        #nn.init.constant_(self.classifier.weight, 0.25)\n","        #nn.init.constant_(self.classifier.bias, 0)\n","\n","        print('initialization done')\n","\n","    def get_weights(self):\n","        conv_weights = []\n","        bn_weights = []\n","        relu_weights = []\n","        for pname, p in self.named_parameters():\n","            if 'bn' in pname:\n","                bn_weights.append(p)\n","            elif 'relu' in pname:\n","                relu_weights.append(p)\n","            else:\n","                conv_weights.append(p)\n","\n","        return conv_weights, bn_weights, relu_weights\n","\n","    def forward(self, x):\n","        H, W = x.size()[2:]\n","        #x = self.init_block(x)\n","\n","        # encoding path\n","        x1 = self.Conv1(x)\n","\n","        x2 = self.Maxpool(x1)\n","        x2 = self.Conv2(x2)\n","        \n","        x3 = self.Maxpool(x2)\n","        x3 = self.Conv3(x3)\n","\n","        x4 = self.Maxpool(x3)\n","        x4 = self.Conv4(x4)\n","\n","        x5 = self.Maxpool(x4)\n","        x5 = self.Conv5(x5)\n","\n","        #x5 = self.middle_1(x5)\n","        #x5 = self.middle_2(x5)\n","\n","        # decoding + concat path\n","        d5 = self.Up5(x5)\n","        if self.ta:\n","            x4 = self.Att5(d5,x4)\n","        d5 = torch.cat((x4,d5),dim=1)\n","        d5 = self.Up_conv5(d5)\n","        \n","        d4 = self.Up4(d5)\n","        if self.ta:\n","            x3 = self.Att4(d4,x3)\n","        d4 = torch.cat((x3,d4),dim=1)\n","        d4 = self.Up_conv4(d4)\n","\n","        d3 = self.Up3(d4)\n","        if self.ta:\n","            x2 = self.Att3(d3,x2)\n","        d3 = torch.cat((x2,d3),dim=1)\n","        d3 = self.Up_conv3(d3)\n","\n","        d2 = self.Up2(d3)\n","        if self.ta:\n","            x1 = self.Att2(d2,x1)\n","        d2 = torch.cat((x1,d2),dim=1)\n","        d2 = self.Up_conv2(d2)\n","\n","        x_fuses = []\n","        if self.sa and self.dil is not None:\n","            for i, xi in enumerate([d2,d3,d4,d5]):\n","                x_fuses.append(self.attentions[i](self.dilations[i](xi)))\n","        elif self.sa:\n","            for i, xi in enumerate([d2,d3,d4,d5]):\n","                x_fuses.append(self.attentions[i](xi))\n","        elif self.dil is not None:\n","            for i, xi in enumerate([d2,d3,d4,d5]):\n","                x_fuses.append(self.dilations[i](xi))\n","        else:\n","            x_fuses = [d2,d3,d4,d5]\n","\n","        e1 = self.conv_reduces[0](x_fuses[0])\n","        e1 = F.interpolate(e1, (H, W), mode=\"bilinear\", align_corners=False)\n","\n","        e2 = self.conv_reduces[1](x_fuses[1])\n","        e2 = F.interpolate(e2, (H, W), mode=\"bilinear\", align_corners=False)\n","\n","        e3 = self.conv_reduces[2](x_fuses[2])\n","        e3 = F.interpolate(e3, (H, W), mode=\"bilinear\", align_corners=False)\n","\n","        e4 = self.conv_reduces[3](x_fuses[3])\n","        e4 = F.interpolate(e4, (H, W), mode=\"bilinear\", align_corners=False)\n","\n","        outputs = [e1, e2, e3, e4]\n","\n","        output = self.classifier(torch.cat(outputs, dim=1))\n","        #outputs.append(output)\n","        #outputs = [nn.Softmax(r) for r in outputs] #torch.sigmoid\n","        output = self.softmax(output)\n","        return output \n","\n","'''def pidinet_tiny(args):\n","    pdcs = config_model(args.config)\n","    dil = 8 if args.dil else None\n","    return PiDiNet(20, pdcs, dil=dil, sa=args.sa)\n","\n","def pidinet_small(args):\n","    pdcs = config_model(args.config)\n","    dil = 12 if args.dil else None\n","    return PiDiNet(30, pdcs, dil=dil, sa=args.sa)\n","\n","def pidinet(args):\n","    pdcs = config_model(args.config)\n","    dil = 24 if args.dil else None\n","    return PiDiNet(60, pdcs, dil=dil, sa=args.sa)\n","\n","\n","\n","## convert pidinet to vanilla cnn\n","\n","def pidinet_tiny_converted(args):\n","    pdcs = config_model_converted(args.config)\n","    dil = 8 if args.dil else None\n","    return PiDiNet(20, pdcs, dil=dil, sa=args.sa, convert=True)\n","\n","def pidinet_small_converted(args):\n","    pdcs = config_model_converted(args.config)\n","    dil = 12 if args.dil else None\n","    return PiDiNet(30, pdcs, dil=dil, sa=args.sa, convert=True)\n","\n","def pidinet_converted(args):\n","    pdcs = config_model_converted(args.config)\n","    dil = 24 if args.dil else None\n","    return PiDiNet(60, pdcs, dil=dil, sa=args.sa, convert=True)'''"],"metadata":{"id":"Ow1ZF-Byj8Uj","colab":{"base_uri":"https://localhost:8080/","height":154},"executionInfo":{"status":"ok","timestamp":1648128270524,"user_tz":-420,"elapsed":560,"user":{"displayName":"Hai Ninh Nham Do","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj71NWKYnSKJmvjkMKuN-TGjfdJzXtd8JZNf4r7=s64","userId":"15777938739034634289"}},"outputId":"ca0595f0-1ac9-4978-93b3-ce47e0902cb8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'def pidinet_tiny(args):\\n    pdcs = config_model(args.config)\\n    dil = 8 if args.dil else None\\n    return PiDiNet(20, pdcs, dil=dil, sa=args.sa)\\n\\ndef pidinet_small(args):\\n    pdcs = config_model(args.config)\\n    dil = 12 if args.dil else None\\n    return PiDiNet(30, pdcs, dil=dil, sa=args.sa)\\n\\ndef pidinet(args):\\n    pdcs = config_model(args.config)\\n    dil = 24 if args.dil else None\\n    return PiDiNet(60, pdcs, dil=dil, sa=args.sa)\\n\\n\\n\\n## convert pidinet to vanilla cnn\\n\\ndef pidinet_tiny_converted(args):\\n    pdcs = config_model_converted(args.config)\\n    dil = 8 if args.dil else None\\n    return PiDiNet(20, pdcs, dil=dil, sa=args.sa, convert=True)\\n\\ndef pidinet_small_converted(args):\\n    pdcs = config_model_converted(args.config)\\n    dil = 12 if args.dil else None\\n    return PiDiNet(30, pdcs, dil=dil, sa=args.sa, convert=True)\\n\\ndef pidinet_converted(args):\\n    pdcs = config_model_converted(args.config)\\n    dil = 24 if args.dil else None\\n    return PiDiNet(60, pdcs, dil=dil, sa=args.sa, convert=True)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["'''x = torch.rand(1,3,256,256)\n","model = PiDiNet()\n","print(model(x).shape)'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UeuPp5Ek-nL_","executionInfo":{"status":"ok","timestamp":1648128271684,"user_tz":-420,"elapsed":1168,"user":{"displayName":"Hai Ninh Nham Do","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj71NWKYnSKJmvjkMKuN-TGjfdJzXtd8JZNf4r7=s64","userId":"15777938739034634289"}},"outputId":"8d77acb0-0658-4213-a24d-58ae94cb1dfa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["initialization done\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:443: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:647.)\n","  self.padding, self.dilation, self.groups)\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([1, 2, 256, 256])\n"]}]}]}
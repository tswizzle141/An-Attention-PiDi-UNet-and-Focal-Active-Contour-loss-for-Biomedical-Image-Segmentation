{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocessing_2D (copy).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"eKLcUUwjEAog","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648986200036,"user_tz":-420,"elapsed":21323,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"}},"outputId":"cdde6bb0-188d-487c-f6e6-ecba4a62ec86"},"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"C21r7gQiGOFF"},"source":["from IPython.display import clear_output\n","import nibabel as nib\n","import glob \n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import torch.nn.functional as F\n","from PIL import Image\n","from fastprogress import master_bar, progress_bar\n","from torchvision import transforms\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader,Dataset\n","import matplotlib.pyplot as plt\n","# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","clear_output()\n","NUM_CLASS = 2\n","\n","#%cd '/content/drive/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-fN8CSyWKOA"},"source":["'''#!wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Training_Input.zip -O b.zip\n","#!unzip b.zip\n","#!wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1_Training_GroundTruth.zip -O a.zip\n","#!unzip a.zip\n","# !wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Validation_Input.zip -O h.zip\n","# !unzip h.zip\n","# !wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1_Validation_GroundTruth.zip -O j.zip\n","# !unzip j.zip\n","!wget https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Training_Data.zip -O c.zip\n","!unzip c.zip\n","!wget https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Training_Part1_GroundTruth.zip -O d.zip\n","!unzip d.zip\n","!wget https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Test_v2_Data.zip -O e.zip\n","!unzip e.zip\n","!wget https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Test_v2_Part1_GroundTruth.zip -O f.zip\n","!unzip f.zip\n","# !wget https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Validation_Data.zip -O g.zip\n","# !unzip g.zip\n","# clear_output()'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uuTJQu_EZq5t"},"source":["#train_path = sorted(glob.glob(\"/content/ISIC2018_Task1-2_Training_Input/*\"))\n","#mask_path = sorted(glob.glob(\"/content/ISIC2018_Task1_Training_GroundTruth/*png\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lU1B2dQt-0B6"},"source":["#ISIC17\n","#a = sorted(glob.glob(\"/content/ISIC-2017_Training_Data/*png\"))\n","#b = sorted(glob.glob(\"/content/ISIC-2017_Training_Part1_GroundTruth/*png\"))\n","#c = sorted(glob.glob(\"/content/ISIC-2017_Test_v2_Data/*png\"))\n","#d = sorted(glob.glob(\"/content/ISIC-2017_Test_v2_Part1_GroundTruth/*png\"))\n","\n","#PH2\n","#a = sorted(glob.glob(\"/content/drive/MyDrive/Global-Local Image-based Active Contour Loss for Multiclass Medical Image Segmentation with Deep Learning/ISIC/PH2/train/image/*png\"))\n","#b = sorted(glob.glob(\"/content/drive/MyDrive/Global-Local Image-based Active Contour Loss for Multiclass Medical Image Segmentation with Deep Learning/ISIC/PH2/train/label/*png\"))\n","#c = sorted(glob.glob(\"/content/drive/MyDrive/Global-Local Image-based Active Contour Loss for Multiclass Medical Image Segmentation with Deep Learning/ISIC/PH2/test/image/*png\"))\n","#d = sorted(glob.glob(\"/content/drive/MyDrive/Global-Local Image-based Active Contour Loss for Multiclass Medical Image Segmentation with Deep Learning/ISIC/PH2/test/label/*png\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"utEEMS-0uSQu","executionInfo":{"status":"ok","timestamp":1648986599453,"user_tz":-420,"elapsed":5,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"}},"outputId":"43a3d51a-570a-44fa-ff3f-8f91c9e7c985"},"source":["#%cd '/content/drive/MyDrive/Global-Local Image-based Active Contour Loss for Multiclass Medical Image Segmentation with Deep Learning/ISIC/PH2/'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1tJB_mOS2BR5VkTrdaHMsYcmaQ97B-1ir/data_seg\n"]}]},{"cell_type":"code","metadata":{"id":"75HS5ntrx1_B"},"source":["def get_data(train_path, mask_path, size=(192, 256)):\n","    from tqdm import tqdm\n","    images, masks = [], []\n","    for idx in tqdm(range(len(train_path))):\n","        image = Image.open(train_path[idx]).resize((size[1], size[0]))\n","        mask = Image.open(mask_path[idx]).resize((size[1], size[0]), Image.NEAREST)\n","        mask = np.array(mask) // 255\n","        images.append(image)\n","        masks.append(mask)\n","    return np.stack(images), np.stack(masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XNxTK84xsQI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648908937747,"user_tz":-420,"elapsed":757641,"user":{"displayName":"Hai Ninh Nham Do","userId":"04781574181607807616"}},"outputId":"3325e7d4-ab37-430f-c1e2-c2611eaf0383"},"source":["#x_train, y_train = get_data(a, b)\n","#x_test, y_test = get_data(c, d)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2000/2000 [07:00<00:00,  4.75it/s]\n","100%|██████████| 600/600 [05:35<00:00,  1.79it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"dPf3mUoj455y"},"source":["#np.savez_compressed('/content/drive/MyDrive/Global-Local Image-based Active Contour Loss for Multiclass Medical Image Segmentation with Deep Learning/ISIC/dataISIC2018/ISIC2017_192_256_train', image=x_train, mask=y_train)\n","#np.savez_compressed('/content/drive/MyDrive/Global-Local Image-based Active Contour Loss for Multiclass Medical Image Segmentation with Deep Learning/ISIC/dataISIC2018/ISIC2017_192_256_test', image=x_test, mask=y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YYH1ya6zZ83f"},"source":["# data = np.load(\"/content/drive/MyDrive/new_paper/ISIC/dataISIC2018/ISIC2018_192_256.npz\")\n","# x,y = data[\"image\"], data[\"mask\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bLqYno7Qfj_H"},"source":["class RandomCrop(transforms.RandomResizedCrop):\n","    def __call__(self, imgs):\n","        i, j, h, w = self.get_params(imgs[0], self.scale, self.ratio)\n","        for imgCount in range(len(imgs)):\n","            imgs[imgCount] = transforms.functional.resized_crop(imgs[imgCount], i, j, h, w, self.size, self.interpolation)\n","        return imgs\n","class ISICLoader(Dataset):\n","    def __init__(self, images, masks, \n","                 transform=True, typeData = \"train\"):\n","        self.transform = transform if typeData == \"train\" else False  # augment data bool\n","        self.typeData = typeData\n","        self.images = images\n","        self.masks = masks\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def rotate(self, image, mask, degrees=(-15,15), p=0.1):\n","        if torch.rand(1) < p:\n","            degree = np.random.uniform(*degrees)\n","            image = image.rotate(degree, Image.NEAREST)\n","            mask = mask.rotate(degree, Image.NEAREST)\n","        return image, mask\n","    def horizontal_flip(self, image, mask, p=0.5):\n","        if torch.rand(1) < p:\n","            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n","            mask = mask.transpose(Image.FLIP_LEFT_RIGHT)\n","        return image, mask\n","    def vertical_flip(self, image, mask, p=0.5):\n","        if torch.rand(1) < p:\n","            image = image.transpose(Image.FLIP_TOP_BOTTOM)\n","            mask = mask.transpose(Image.FLIP_TOP_BOTTOM)\n","        return image, mask\n","    def random_resized_crop(self, image, mask, p=0.5):\n","        if torch.rand(1) < p:\n","            image, mask = RandomCrop((192, 256), scale=(0.8, 0.95))([image, mask])\n","        return image, mask\n","\n","    def augment(self, image, mask):\n","        image, mask = self.random_resized_crop(image, mask)\n","        image, mask = self.rotate(image, mask)\n","        image, mask = self.horizontal_flip(image, mask)\n","        image, mask = self.vertical_flip(image, mask)\n","        return image, mask\n","\n","    def __getitem__(self, idx):\n","        image = Image.fromarray(self.images[idx])\n","        mask = Image.fromarray(self.masks[idx])\n","    ####################### augmentation data ##############################\n","        if self.transform:\n","            image, mask = self.augment(image, mask)\n","        image = transforms.ToTensor()(image)\n","        mask = np.asarray(mask, np.int64)\n","        mask = torch.from_numpy(mask[np.newaxis])\n","        return image, mask"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iDaXFr94eodZ"},"source":["##loss"]},{"cell_type":"code","metadata":{"id":"lpy56sQyeuvg"},"source":["class SemiActiveLoss(nn.Module):\n","    def __init__(self, device, alpha =1e-9, beta = 1e-1, lamda = 1e-3):\n","        super().__init__()\n","        self.device = device\n","        self.alpha = alpha\n","        self.beta = beta      \n","        self.lamda = lamda\n","    def LevelsetLoss(self, image, y_pred, kernel_size=5, smooth=1e-5):\n","        kernel = torch.ones(1, y_pred.size(1), kernel_size, kernel_size, device=self.device) / kernel_size**2\n","        padding = kernel_size //2\n","        lossRegion = 0.0\n","        y_pred_fuzzy = y_pred \n","        for ich in range(image.size(1)):\n","            target_ = image[:,ich:ich+1] \n","            pcentroid_local = F.conv2d(target_ * y_pred_fuzzy + smooth, kernel, padding = padding) \\\n","                                / F.conv2d(y_pred_fuzzy + smooth, kernel, padding = padding)\n","            plevel_local = target_ - pcentroid_local\n","            loss_local = plevel_local * plevel_local * y_pred_fuzzy\n","\n","            pcentroid_global = torch.sum(target_ * y_pred_fuzzy, dim=(2,3),keepdim=True) \\\n","                                / torch.sum(y_pred_fuzzy+smooth, dim=(2,3),keepdim = True)   \n","            plevel_global = target_ - pcentroid_global\n","            loss_global = plevel_global * plevel_global * y_pred_fuzzy\n","\n","            lossRegion += torch.sum(loss_local) + self.beta * torch.sum(loss_global)\n","        return lossRegion \n","    def GradientLoss(self, y_pred, penalty = \"l1\"):\n","        dH = torch.abs(y_pred[...,1:] - y_pred[...,:-1])\n","        dW = torch.abs(y_pred[:,:,1:] - y_pred[:,:,:-1])\n","        if penalty == \"l2\":\n","            dH = dH * dH\n","            dW = dW * dW\n","        loss =  torch.sum(dH) +  torch.sum(dW)\n","        return loss\n","    def ActiveContourLoss(self, y_true, y_pred, smooth=1e-11):   \n","        dim = (1,2,3)\n","        yTrueOnehot = torch.zeros(y_true.size(0), NUM_CLASS, y_true.size(2), y_true.size(3), device=self.device)\n","        yTrueOnehot = torch.scatter(yTrueOnehot, 1, y_true, 1)[:,1:]\n","        y_pred = y_pred[:,1:]\n","\n","        active = - torch.log(1-y_pred+smooth) * (1-yTrueOnehot) - torch.log(y_pred+smooth) * yTrueOnehot\n","        loss = torch.sum(active, dim = dim) / torch.sum(yTrueOnehot + y_pred - yTrueOnehot * y_pred + smooth, dim = dim)\n","        return torch.mean(loss)\n","\n","    def forward(self, image, y_true, y_pred):\n","        active = self.ActiveContourLoss(y_true, y_pred)\n","        levelset =  self.LevelsetLoss(image, y_pred)\n","        length = self.GradientLoss(y_pred)\n","        return active + self.alpha * (levelset + self.lamda * length) \n","class CrossEntropy(nn.Module):\n","    def __init__(self, device):\n","        super().__init__()\n","        self.device = device\n","    def forward(self, y_true, y_pred):   \n","        yTrueOnehot = torch.zeros(y_true.size(0), NUM_CLASS, y_true.size(2), y_true.size(3), device=self.device)\n","        yTrueOnehot = torch.scatter(yTrueOnehot, 1, y_true, 1)\n","\n","        loss = torch.sum(-yTrueOnehot * torch.log(y_pred+1e-10))\n","        return loss / (y_true.size(0) * y_true.size(2) * y_true.size(3))\n","class DiceLoss(nn.Module):\n","    def __init__(self, device):\n","        super().__init__()\n","        self.device = device\n","    def forward(self, y_true, y_pred):   \n","        yTrueOnehot = torch.zeros(y_true.size(0), NUM_CLASS, y_true.size(2), y_true.size(3), device=self.device)\n","        yTrueOnehot = torch.scatter(yTrueOnehot, 1, y_true, 1)[:, 1:]\n","        y_pred = y_pred[:,1:]\n","\n","        intersection = torch.sum(yTrueOnehot * y_pred, dim=[1,2,3])\n","        cardinality  = torch.sum(yTrueOnehot + y_pred , dim=[1,2,3])\n","        loss = 1.0-torch.mean((2. * intersection + 1e-5) / (cardinality + 1e-5))\n","        return loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DnPx9nmRfEyp"},"source":["##metrics"]},{"cell_type":"code","metadata":{"id":"IGrw4VZPfGQ3"},"source":["def dice(y_true, y_pred, smooth = 1e-4):\n","    y_pred = torch.argmax(y_pred, dim=1, keepdim = True)\n","    intersection = torch.sum(y_true * y_pred, dim=[1,2,3])\n","    cardinality  = torch.sum(y_true + y_pred , dim=[1,2,3])\n","    return torch.mean((2. * intersection + smooth) / (cardinality + smooth), dim=0)\n","\n","def jaccard(y_true, y_pred, smooth = 1e-4):\n","    y_pred = torch.argmax(y_pred, dim=1, keepdim = True)\n","    intersection = torch.sum(y_true * y_pred, dim=[1,2,3])\n","    union = torch.sum(y_true + y_pred , dim=[1,2,3]) - intersection\n","    return torch.mean((intersection + smooth) / (union + smooth), dim=0)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B65eOb4VOE4G"},"source":["##optimizer"]},{"cell_type":"code","metadata":{"id":"fYPf1-J-OGl8"},"source":["import math\n","import torch\n","from torch.optim.optimizer import Optimizer\n","\n","\n","class Nadam(Optimizer):\n","    \"\"\"Implements Nadam algorithm (a variant of Adam based on Nesterov momentum).\n","    It has been proposed in `Incorporating Nesterov Momentum into Adam`__.\n","    Arguments:\n","        params (iterable): iterable of parameters to optimize or dicts defining\n","            parameter groups\n","        lr (float, optional): learning rate (default: 2e-3)\n","        betas (Tuple[float, float], optional): coefficients used for computing\n","            running averages of gradient and its square\n","        eps (float, optional): term added to the denominator to improve\n","            numerical stability (default: 1e-8)\n","        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n","        schedule_decay (float, optional): momentum schedule decay (default: 4e-3)\n","    __ http://cs229.stanford.edu/proj2015/054_report.pdf\n","    __ http://www.cs.toronto.edu/~fritz/absps/momentum.pdf\n","        Originally taken from: https://github.com/pytorch/pytorch/pull/1408\n","        NOTE: Has potential issues but does work well on some problems.\n","    \"\"\"\n","\n","    def __init__(self, params, lr=2e-3, betas=(0.9, 0.999), eps=1e-8,\n","                 weight_decay=0, schedule_decay=4e-3):\n","        if not 0.0 <= lr:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        defaults = dict(\n","            lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, schedule_decay=schedule_decay)\n","        super(Nadam, self).__init__(params, defaults)\n","\n","    @torch.no_grad()\n","    def step(self, closure=None):\n","        \"\"\"Performs a single optimization step.\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            with torch.enable_grad():\n","                loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    state['m_schedule'] = 1.\n","                    state['exp_avg'] = torch.zeros_like(p)\n","                    state['exp_avg_sq'] = torch.zeros_like(p)\n","\n","                # Warming momentum schedule\n","                m_schedule = state['m_schedule']\n","                schedule_decay = group['schedule_decay']\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","                beta1, beta2 = group['betas']\n","                eps = group['eps']\n","                state['step'] += 1\n","                t = state['step']\n","                bias_correction2 = 1 - beta2 ** t\n","\n","                if group['weight_decay'] != 0:\n","                    grad = grad.add(p, alpha=group['weight_decay'])\n","\n","                momentum_cache_t = beta1 * (1. - 0.5 * (0.96 ** (t * schedule_decay)))\n","                momentum_cache_t_1 = beta1 * (1. - 0.5 * (0.96 ** ((t + 1) * schedule_decay)))\n","                m_schedule_new = m_schedule * momentum_cache_t\n","                m_schedule_next = m_schedule * momentum_cache_t * momentum_cache_t_1\n","                state['m_schedule'] = m_schedule_new\n","\n","                # Decay the first and second moment running average coefficient\n","                exp_avg.mul_(beta1).add_(grad, alpha=1. - beta1)\n","                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1. - beta2)\n","\n","                denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n","                p.addcdiv_(grad, denom, value=-group['lr'] * (1. - momentum_cache_t) / (1. - m_schedule_new))\n","                p.addcdiv_(exp_avg, denom, value=-group['lr'] * momentum_cache_t_1 / (1. - m_schedule_next))\n","\n","        return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTSUV46AqmRV"},"source":["# train_input = sorted(glob.glob(\"/content/ISIC2018_Task1-2_Training_Input/*jpg\"))\n","# train_gt = sorted(glob.glob(\"/content/ISIC2018_Task1_Training_GroundTruth/*png\"))\n","# valid_input = sorted(glob.glob(\"/content/ISIC2018_Task1-2_Validation_Input/*jpg\"))\n","# valid_gt = sorted(glob.glob(\"/content/ISIC2018_Task1_Validation_GroundTruth/*png\"))\n","# inputs = valid_input + train_input\n","# gts = valid_gt + train_gt\n","# train_valid_test_split = (0.8, 0.1, 0.1)\n","\n","# test_count = int(train_valid_test_split[2] * len(inputs))\n","# valid_count = test_count\n","# train_count = len(inputs) - test_count * 2\n","\n","# all_files = np.array(list(zip(inputs, gts)))\n","# np.random.seed(42)\n","# np.random.shuffle(all_files)\n","\n","# train_files = all_files[:train_count]\n","# valid_files = all_files[train_count : train_count + valid_count]\n","# test_files = all_files[-test_count:]\n","\n","# def get_data(files, size=(192, 256)):\n","#     from tqdm import tqdm\n","#     images, masks = [], []\n","#     for input_file, gt_file in tqdm(files):\n","#         image = Image.open(input_file).resize((size[1], size[0]))\n","#         mask = Image.open(gt_file).resize((size[1], size[0]), Image.NEAREST)\n","#         mask = np.array(mask) // 255\n","#         images.append(image)\n","#         masks.append(mask)\n","#     return np.stack(images), np.stack(masks)\n","# x_train, y_train =  get_data(train_files) \n","# x_val, y_val =  get_data(valid_files) \n","# x_test, y_test =  get_data(test_files) \n","# %cd /content/drive/MyDrive/dataISIC2018\n","# np.savez_compressed('ISIC2018_train', image=x_train, mask=y_train)\n","# np.savez_compressed('ISIC2018_val', image=x_val, mask=y_val)\n","# np.savez_compressed('ISIC2018_test', image=x_test, mask=y_test)\n"],"execution_count":null,"outputs":[]}]}